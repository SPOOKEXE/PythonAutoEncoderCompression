{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b0c6ba-5805-4067-b475-4b303d72526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 3)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (2500, 3)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (2500, 7500)              30000     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (2500, 1875)              14064375  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (2500, 300)               562800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (2500, 27)                8127      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14665302 (55.94 MB)\n",
      "Trainable params: 14665302 (55.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (1, 27)                   756       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, 300)                  8400      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (1, 1875)                 564375    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (1, 7500)                 14070000  \n",
      "                                                                 \n",
      " reshape (Reshape)           (1, 2500, 3)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14643531 (55.86 MB)\n",
      "Trainable params: 14643531 (55.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None None\n",
      "(1000, 2500, 3) [[145 106 155]\n",
      " [ 59  97  56]\n",
      " [ 47 111  68]\n",
      " ...\n",
      " [ 19  66 239]\n",
      " [146 181 136]\n",
      " [138 175 242]]\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file135ql8c1.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'simple_auto_encoder_3' (type SimpleAutoEncoder).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_473/3986738986.py\", line 50, in call  *\n            encoded = self.encoder( x )\n        File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'encoder' (type Sequential).\n        \n        Input 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 7500)\n        \n        Call arguments received by layer 'encoder' (type Sequential):\n          • inputs=tf.Tensor(shape=(None, 2500, 3), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'simple_auto_encoder_3' (type SimpleAutoEncoder):\n      • x=tf.Tensor(shape=(None, 2500, 3), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m encoded_imgs \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencoder(x_test)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     82\u001b[0m decoded_imgs \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mdecoder(encoded_imgs)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filen22q5epa.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file135ql8c1.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m encoded \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mencoder, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m decoded \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdecoder, (ag__\u001b[38;5;241m.\u001b[39mld(encoded),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file135ql8c1.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'simple_auto_encoder_3' (type SimpleAutoEncoder).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_473/3986738986.py\", line 50, in call  *\n            encoded = self.encoder( x )\n        File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/user/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'encoder' (type Sequential).\n        \n        Input 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 7500)\n        \n        Call arguments received by layer 'encoder' (type Sequential):\n          • inputs=tf.Tensor(shape=(None, 2500, 3), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'simple_auto_encoder_3' (type SimpleAutoEncoder):\n      • x=tf.Tensor(shape=(None, 2500, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from random import randint\n",
    "\n",
    "# https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n",
    "# https://www.tensorflow.org/tutorials/generative/autoencoder\n",
    "\n",
    "# disable gpu (only enable cpu)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "class NumberVectorGenerator:\n",
    "\n",
    "    @staticmethod\n",
    "    def generate( shape : tuple ) -> np.ndarray:\n",
    "        return np.random.randint(low=0, high=255, size=shape)\n",
    "\n",
    "class SimpleAutoEncoder(keras.Model):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(SimpleAutoEncoder, self).__init__()\n",
    "\n",
    "        self.shape = shape\n",
    "        print(shape)\n",
    "        self.encoder = keras.Sequential([\n",
    "            keras.layers.Flatten(name='flatten'),\n",
    "            keras.layers.Dense(shape[0]*shape[1], activation='relu', name='dense_1'),\n",
    "            keras.layers.Dense(25*25*3, activation='relu', name='dense_2'),\n",
    "            keras.layers.Dense(10*10*3, activation='relu', name='dense_3'),\n",
    "            keras.layers.Dense(3*3*3, activation='relu', name='dense_4'),\n",
    "        ], name=\"encoder\")\n",
    "        self.encoder.build(input_shape=shape)\n",
    "    \n",
    "        self.decoder = keras.Sequential([\n",
    "            keras.layers.Dense(3*3*3, activation='relu', name='dense_1'),\n",
    "            keras.layers.Dense(10*10*3, activation='relu', name='dense_2'),\n",
    "            keras.layers.Dense(25*25*3, activation='relu', name='dense_3'),\n",
    "            keras.layers.Dense(shape[0]*shape[1], activation='sigmoid', name='dense_4'),\n",
    "            keras.layers.Reshape(target_shape=shape, name='reshape'),\n",
    "        ], name=\"decoder\")\n",
    "        self.decoder.build(input_shape=(1,3*3*3))\n",
    "\n",
    "    def call( self, x ) -> tuple:\n",
    "        # print( np.shape(x) )\n",
    "        encoded = self.encoder( x )\n",
    "        # print( np.shape(encoded) )\n",
    "        decoded = self.decoder(encoded)\n",
    "        # print( np.shape(decoded) )\n",
    "        return decoded\n",
    "\n",
    "_shape = (50*50, 3)\n",
    "\n",
    "autoencoder = SimpleAutoEncoder(shape=_shape)\n",
    "autoencoder.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "print(autoencoder.encoder.summary(), autoencoder.decoder.summary())\n",
    "\n",
    "data = NumberVectorGenerator.generate( (1000, _shape[0], _shape[1]) )\n",
    "print( np.shape(data), data[randint(1, len(data)-1 )] )\n",
    "\n",
    "# split training set\n",
    "x_train, x_test = train_test_split( data, test_size=0.3, shuffle=True )\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# fit\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=12,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, x_test),\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "\n",
    "# n = 10\n",
    "# plt.figure(figsize=(20, 4))\n",
    "# for i in range(n):\n",
    "#     # display original\n",
    "#     ax = plt.subplot(2, n, i + 1)\n",
    "#     plt.imshow(x_test[i])\n",
    "#     plt.title(\"original\")\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#     # display reconstruction\n",
    "#     ax = plt.subplot(2, n, i + 1 + n)\n",
    "#     plt.imshow(decoded_imgs[i])\n",
    "#     plt.title(\"reconstructed\")\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d2111-2178-471b-b7a9-9ad7b569d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "from typing import Any\n",
    "\n",
    "def slice_to_chunks( array : list, chunk_size : int ) -> list:\n",
    "    for i in range(0, len(array), chunk_size):  \n",
    "        yield array[i:i + chunk_size]\n",
    "\n",
    "def split_into_chunks( pixel_array : list, chunk_size : int, blank_values : Any ) -> list:\n",
    "    chunks = list( slice_to_chunks( pixel_array, chunk_size ) )\n",
    "    chunks[-1].extend([ blank_values ] * (chunk_size - len( chunks[-1] )))\n",
    "    return chunks\n",
    "\n",
    "def encode_image( img : Image.Image ) -> np.ndarray:\n",
    "    # image dimensions\n",
    "    print( \"Input Image Shape;\", img.size[::-1] )\n",
    "    \n",
    "    # removes alpha by using only RGB\n",
    "    img = img.convert('RGB')\n",
    "    \n",
    "    # read the pixels from the image\n",
    "    pixels_d2 = np.array(img).tolist()\n",
    "    \n",
    "    # get the complete flattened pixel array\n",
    "    pixel_array = []\n",
    "    for col in pixels_d2:\n",
    "        pixel_array.extend(col)\n",
    "    print( \"Total Pixels; \", len(pixel_array))\n",
    "\n",
    "    #chunk the pixels\n",
    "    print(\"Chunking Arrays\")\n",
    "    chunked = np.array( split_into_chunks( pixel_array, _shape[0], [0,0,0] ) )\n",
    "    print(\"Chunked Arrays: \", len(chunked))\n",
    "    \n",
    "    # encode the values\n",
    "    print(\"Encoding\")\n",
    "    encoded_values = autoencoder.encoder([chunked]).numpy().tolist()\n",
    "    print(\"Encoded\")\n",
    "\n",
    "    # return the encoded values list\n",
    "    return encoded_values\n",
    "\n",
    "def decode_image( values : np.ndarray ) -> Image.Image:\n",
    "    pass # decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "\n",
    "img = Image.open(\"/mnt/c/Users/Declan/Downloads/31tkCSZqN3L_2.png\")\n",
    "print(img.size)\n",
    "\n",
    "encoded = encode_image( img )\n",
    "print(np.shape(encoded))\n",
    "\n",
    "with open(\"/mnt/c/Users/Declan/Downloads/out.json\", \"w\") as file:\n",
    "    file.write( json.dumps(encoded) )\n",
    "\n",
    "# decoded = decode_image( encoded )\n",
    "# print(decoded.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8601ec-a24d-45d4-ba03-6e9139d284c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
